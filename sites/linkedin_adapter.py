# sites/linkedin_adapter.py
from __future__ import annotations
from playwright.async_api import Page
from typing import Optional, List, Dict
from urllib.parse import urljoin, urlparse, parse_qs
import re
from pathlib import Path

# =============== å°å·¥å…· ===============
def _norm(s: Optional[str]) -> Optional[str]:
    if not s:
        return None
    s = " ".join(s.split())
    return s or None

def _job_id_from_link(href: str) -> str:
    """ä» /jobs/view/123456789/ æˆ– ?currentJobId=123456 æå– job_id"""
    if not href:
        return ""
    try:
        u = urlparse(href)
        qs = parse_qs(u.query or "")
        jid = qs.get("currentJobId", [None])[0]
        if jid:
            return jid
    except Exception:
        pass
    m = re.search(r"/jobs/view/(\d+)", href)
    return m.group(1) if m else (href or "")

async def _text_first(root, selectors: List[str]) -> Optional[str]:
    for sel in selectors:
        el = await root.query_selector(sel)
        if el:
            try:
                t = await el.inner_text()
                t = _norm(t)
                if t:
                    return t
            except Exception:
                pass
    return None

# åªè¦é¡µé¢é‡Œå‡ºç°â€œæŸ¥çœ‹èŒä½â€çš„é“¾æ¥å°±ç®—æœ‰å¡ç‰‡
JOB_LINK_SEL = 'a[href*="/jobs/view/"]'


# =============== é€‚é…å™¨ ===============
async def extract_linkedin_jobs(page: Page) -> List[Dict]:
    """
    æ›´ç¨³å¥çš„ LinkedIn åˆ—è¡¨æŠ“å–ï¼š
    - ä¸ä¾èµ–å›ºå®šçš„ ul.jobs-search__results-list
    - ä»¥ a[href*="/jobs/view/"] ä¸ºåŸºå‡†æŠ“å–
    - å¤„ç†æ‡’åŠ è½½/å¼¹çª—/æ— ç»“æœ
    """
    # é¿å…ç”¨ page.content()ï¼ˆå¯¼èˆªæœŸæ˜“æŠ¥é”™ï¼‰ï¼Œæ”¹ä¸º evaluate è¯»å–å¯è§æ–‡æœ¬
    url_lc = (page.url or "").lower()
    try:
        html_text = await page.evaluate("() => document.body ? document.body.innerText : ''")
        html_lc = (html_text or "").lower()
    except Exception:
        html_lc = ""

    # ç™»å½•/é£æ§é¡µæ£€æµ‹
    if ("linkedin.com/checkpoint" in url_lc) or ("linkedin.com/login" in url_lc) or ("sign in" in html_lc):
        print("ğŸ” LinkedIn éœ€è¦ç™»å½•æˆ–é€šè¿‡æ£€æŸ¥ã€‚è¯·å…ˆåœ¨è¯¥ä¸Šä¸‹æ–‡å®Œæˆç™»å½•ã€‚")
        return []

    # ç­‰â€œæœ‰å¡ç‰‡æˆ–æ— ç»“æœâ€ä»»ä¸€æˆç«‹
    try:
        await page.wait_for_function(
            """
            sel => {
              const hasCards = document.querySelectorAll(sel).length > 0;
              const noRes = !!document.querySelector('section.jobs-search__no-results, div.jobs-search-two-pane__no-results');
              return hasCards || noRes;
            }
            """,
            arg=JOB_LINK_SEL,
            timeout=30000
        )
    except Exception:
        # å†ç¼“ä¸€ç¼“
        await page.wait_for_timeout(1200)

    # è½»å¾®æ»šåŠ¨è§¦å‘æ‡’åŠ è½½
    for _ in range(3):
        await page.mouse.wheel(0, 1000)
        await page.wait_for_timeout(400)

    # ç¬¬ä¸€æ¬¡æŠ“
    links = await page.query_selector_all(JOB_LINK_SEL)
    # è‹¥è¿˜å°‘ï¼Œå†æ»šå‡ å±
    if not links:
        for _ in range(6):
            await page.mouse.wheel(0, 1400)
            await page.wait_for_timeout(500)
            links = await page.query_selector_all(JOB_LINK_SEL)
            if links:
                break

    jobs: List[Dict] = []
    seen_ids: set[str] = set()

    # ä¿å­˜å‰å‡ å¼ å¡ç‰‡ HTML ä¾¿äºæ’æŸ¥
    Path("debug_cards").mkdir(exist_ok=True)

    for idx, a in enumerate(links[:6], 1):
        try:
            outer = await a.evaluate("el => (el.closest('li, .base-card, .job-card-container, .jobs-search-results__list-item') || el).outerHTML")
            Path(f"debug_cards/ln_card_{idx}.html").write_text(outer or "", encoding="utf-8")
        except Exception:
            pass

    for a in links:
        try:
            href = await a.get_attribute("href") or ""
            if not href:
                continue

            # job_id
            m = re.search(r"/jobs/view/(\d+)", href)
            if not m:
                continue
            job_id = m.group(1)
            if job_id in seen_ids:
                continue
            seen_ids.add(job_id)

            # æ ‡é¢˜ï¼ˆé“¾æ¥æ–‡æœ¬ï¼‰
            try:
                title = _norm(await a.inner_text()) or "Unknown title"
            except Exception:
                title = "Unknown title"

            # æ‰¾åˆ°å¡ç‰‡å®¹å™¨ï¼ˆå‘ä¸Šæ‰¾å¸¸è§å®¹å™¨ï¼‰
            card_js = await a.evaluate_handle(
                "el => el.closest('li, .base-card, .job-card-container, .jobs-search-results__list-item') || el"
            )
            card = card_js.as_element()

            # å…¬å¸
            company = "Unknown"
            if card:
                company = await _text_first(card, [
                    ".job-card-container__company-name",
                    ".base-search-card__subtitle a",
                    ".base-search-card__subtitle",
                    ".base-card__subtitle a",
                    ".base-card__subtitle",
                    ".artdeco-entity-lockup__subtitle a",
                    ".artdeco-entity-lockup__subtitle span",
                ]) or "Unknown"

            # åœ°ç‚¹
            location = "Unknown"
            if card:
                location = await _text_first(card, [
                    ".job-card-container__metadata-item--location",
                    ".job-card-container__metadata-item",
                    ".base-search-card__metadata > span",
                    ".base-card__metadata > span",
                ]) or "Unknown"

            # è§„èŒƒåŒ–é“¾æ¥ï¼ˆå»æ‰è¿½è¸ªå‚æ•°ï¼‰
            link = href.split("?")[0]
            if not link.startswith("http"):
                link = urljoin("https://www.linkedin.com", link)

            jobs.append({
                "job_id": job_id,
                "title": title,
                "company": company,
                "location": location,
                "link": link,
            })
        except Exception:
            # å•ä¸ªå¡ç‰‡å¤±è´¥ä¸å½±å“æ•´ä½“
            continue

    return jobs
